{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e6af2db-f7b5-40b1-a505-fb9d9f915f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# ðŸ“Œ CELL 1 â€” Imports & Config\n",
    "# ==========================\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CONFIG = {\n",
    "    \"SEED\": 42,\n",
    "    \"IMG_SIZE\": 256,\n",
    "    \"BATCH_SIZE\": 128,         # will be split across both GPUs\n",
    "    \"NUM_WORKERS\": 16,\n",
    "    \"LR\": 1e-4,\n",
    "    \"EPOCHS\": 10,\n",
    "    \"DEVICE\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n",
    "torch.manual_seed(CONFIG[\"SEED\"])\n",
    "np.random.seed(CONFIG[\"SEED\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a9f2730-1bfe-48ad-aadd-f567103ab3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ Loading dataset from cache: defacto_df.pkl\n",
      "Loaded: (229187, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>mask_path</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/media/behzadhassan/datasets/Defacto/defacto-s...</td>\n",
       "      <td>/media/behzadhassan/datasets/Defacto/defacto-s...</td>\n",
       "      <td>0</td>\n",
       "      <td>splicing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/media/behzadhassan/datasets/Defacto/defacto-s...</td>\n",
       "      <td>/media/behzadhassan/datasets/Defacto/defacto-s...</td>\n",
       "      <td>0</td>\n",
       "      <td>splicing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/media/behzadhassan/datasets/Defacto/defacto-s...</td>\n",
       "      <td>/media/behzadhassan/datasets/Defacto/defacto-s...</td>\n",
       "      <td>0</td>\n",
       "      <td>splicing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/media/behzadhassan/datasets/Defacto/defacto-s...</td>\n",
       "      <td>/media/behzadhassan/datasets/Defacto/defacto-s...</td>\n",
       "      <td>0</td>\n",
       "      <td>splicing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/media/behzadhassan/datasets/Defacto/defacto-s...</td>\n",
       "      <td>/media/behzadhassan/datasets/Defacto/defacto-s...</td>\n",
       "      <td>0</td>\n",
       "      <td>splicing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path  \\\n",
       "0  /media/behzadhassan/datasets/Defacto/defacto-s...   \n",
       "1  /media/behzadhassan/datasets/Defacto/defacto-s...   \n",
       "2  /media/behzadhassan/datasets/Defacto/defacto-s...   \n",
       "3  /media/behzadhassan/datasets/Defacto/defacto-s...   \n",
       "4  /media/behzadhassan/datasets/Defacto/defacto-s...   \n",
       "\n",
       "                                           mask_path  label      type  \n",
       "0  /media/behzadhassan/datasets/Defacto/defacto-s...      0  splicing  \n",
       "1  /media/behzadhassan/datasets/Defacto/defacto-s...      0  splicing  \n",
       "2  /media/behzadhassan/datasets/Defacto/defacto-s...      0  splicing  \n",
       "3  /media/behzadhassan/datasets/Defacto/defacto-s...      0  splicing  \n",
       "4  /media/behzadhassan/datasets/Defacto/defacto-s...      0  splicing  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ====================================\n",
    "# ðŸ“Œ CELL 2 â€” Parse DEFACTO dataset (with cache)\n",
    "# ====================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "BASE_PATH = \"/media/behzadhassan/datasets/Defacto/\"\n",
    "\n",
    "DATASET_PATHS = {\n",
    "    'splicing': BASE_PATH + 'defacto-splicing/',\n",
    "    'copymove': BASE_PATH + 'defacto-copymove/',\n",
    "    'inpainting': BASE_PATH + 'defacto-inpainting/',\n",
    "    'face': BASE_PATH + 'defacto-face/'\n",
    "}\n",
    "\n",
    "LABEL_MAP = {\n",
    "    'splicing': 0,\n",
    "    'copymove': 1,\n",
    "    'inpainting': 2,\n",
    "    'face': 3\n",
    "}\n",
    "\n",
    "CACHE_PATH = \"defacto_df.pkl\"\n",
    "\n",
    "\n",
    "# ---------- ORIGINAL SCANNER (only used if cache missing) ----------\n",
    "def collect_defacto():\n",
    "    rows = []\n",
    "\n",
    "    print(\"\\nðŸ” Scanning full DEFACTO dataset...\\n\")\n",
    "\n",
    "    for dtype, root in DATASET_PATHS.items():\n",
    "\n",
    "        print(f\"Processing {dtype.upper()}...\")\n",
    "\n",
    "        img_dirs = sorted(glob(os.path.join(root, \"*_img\")))\n",
    "\n",
    "        for img_dir in tqdm(img_dirs):\n",
    "            image_folder = os.path.join(img_dir, \"img\")\n",
    "            images = sorted(glob(os.path.join(image_folder, \"*.*\")))\n",
    "\n",
    "            annot_dir = img_dir.replace(\"_img\", \"_annotations\")\n",
    "            mask_folder = os.path.join(annot_dir, \"probe_mask\")\n",
    "\n",
    "            for img_path in images:\n",
    "                filename = os.path.basename(img_path).split('.')[0]\n",
    "                if filename.endswith(\".jpg\"):\n",
    "                    filename = filename.replace(\".jpg\", \"\")\n",
    "\n",
    "                mask_matches = glob(os.path.join(mask_folder, f\"{filename}.*\"))\n",
    "                if not mask_matches:\n",
    "                    continue\n",
    "\n",
    "                rows.append({\n",
    "                    \"image_path\": img_path,\n",
    "                    \"mask_path\": mask_matches[0],\n",
    "                    \"label\": LABEL_MAP[dtype],\n",
    "                    \"type\": dtype\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    print(\"\\n====================================\")\n",
    "    print(f\"ðŸ”¥ TOTAL SAMPLES COLLECTED: {len(df)}\")\n",
    "    print(\"====================================\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# ---------- CACHE LOADING ----------\n",
    "if os.path.exists(CACHE_PATH):\n",
    "    print(\"âš¡ Loading dataset from cache:\", CACHE_PATH)\n",
    "    df = pd.read_pickle(CACHE_PATH)\n",
    "    print(\"Loaded:\", df.shape)\n",
    "else:\n",
    "    print(\"ðŸš€ Cache not found â€” scanning now...\")\n",
    "    df = collect_defacto()\n",
    "    df.to_pickle(CACHE_PATH)\n",
    "    print(f\"ðŸ”¥ Cache saved to {CACHE_PATH}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1559032f-fc08-48bb-b819-2707e303c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# ðŸ“Œ CELL 3 â€” Dataset Class + Transformations\n",
    "# ===========================================\n",
    "\n",
    "class DeFactoDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row['image_path']\n",
    "        label = row['label']\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            import tifffile\n",
    "            image = tifffile.imread(img_path)\n",
    "\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)[\"image\"]\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "def get_transforms(img_size):\n",
    "    return A.Compose([\n",
    "        A.RandomResizedCrop(\n",
    "            size=(img_size, img_size),   # required for Albumentations 2.0.8\n",
    "            scale=(0.7, 1.0),\n",
    "            ratio=(0.75, 1.33),\n",
    "            p=1.0\n",
    "        ),\n",
    "\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.2),\n",
    "        A.RandomBrightnessContrast(p=0.4),\n",
    "        A.GaussianBlur(blur_limit=(3, 5), p=0.3),\n",
    "        A.GaussNoise(p=0.3),\n",
    "\n",
    "        # â­ Safe replacement for MaskDropout, Cutout, CoarseDropout\n",
    "        A.GridDropout(\n",
    "            ratio=0.5,\n",
    "            holes_number_x=4,\n",
    "            holes_number_y=4,\n",
    "            p=0.3\n",
    "        ),\n",
    "\n",
    "        A.Normalize(\n",
    "            mean=(0.485, 0.456, 0.406),\n",
    "            std=(0.229, 0.224, 0.225)\n",
    "        ),\n",
    "\n",
    "        ToTensorV2()\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47bb24eb-cf54-4012-b8d6-92c66406d2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2962230/2726931275.py:48: UserWarning: Argument(s) 'holes_number_x, holes_number_y' are not valid for transform GridDropout\n",
      "  A.GridDropout(\n",
      "/home/behzadhassan/anaconda3/envs/dl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# ðŸ“Œ CELL 4 â€” Split + Balanced Sampler\n",
    "# =====================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, stratify=df[\"label\"], random_state=42)\n",
    "\n",
    "def create_balanced_sampler(df):\n",
    "    class_counts = df['label'].value_counts().sort_index().values\n",
    "    class_weights = 1.0 / class_counts\n",
    "    sample_weights = df['label'].map(lambda x: class_weights[x]).values\n",
    "    return WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "\n",
    "train_sampler = create_balanced_sampler(train_df)\n",
    "\n",
    "train_dataset = DeFactoDataset(train_df, transforms=get_transforms(CONFIG[\"IMG_SIZE\"]))\n",
    "val_dataset   = DeFactoDataset(val_df,   transforms=get_transforms(CONFIG[\"IMG_SIZE\"]))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG[\"BATCH_SIZE\"],\n",
    "    sampler=train_sampler,\n",
    "    num_workers=CONFIG[\"NUM_WORKERS\"],\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG[\"BATCH_SIZE\"],\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG[\"NUM_WORKERS\"],\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3978c3f2-71e5-43b2-b518-de3bc90d887c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded previous ResNet50 checkpoint successfully!\n",
      "Using 2 GPUs with DataParallel\n",
      "âš¡ Using LR = 1e-05\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# ðŸ“Œ CELL 5 â€” Load ResNet50 + DataParallel\n",
    "# =====================================\n",
    "\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "def create_resnet50(num_classes=4):\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "    model.fc = nn.Linear(2048, num_classes)\n",
    "    return model\n",
    "\n",
    "# Create model architecture\n",
    "model = create_resnet50(num_classes=4)\n",
    "model = model.to(CONFIG[\"DEVICE\"])\n",
    "\n",
    "# ---- LOAD CHECKPOINT ----\n",
    "checkpoint_path = \"best_resnet50_defacto.pth\"\n",
    "state = torch.load(checkpoint_path, map_location=CONFIG[\"DEVICE\"])\n",
    "\n",
    "# If checkpoint was saved from DataParallel, remove \"module.\" prefixes\n",
    "new_state = OrderedDict()\n",
    "for k, v in state.items():\n",
    "    new_state[k.replace(\"module.\", \"\")] = v\n",
    "\n",
    "model.load_state_dict(new_state)\n",
    "\n",
    "print(\"âœ… Loaded previous ResNet50 checkpoint successfully!\")\n",
    "\n",
    "# ---- MULTI-GPU ----\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs with DataParallel\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# ---- Loss & Optimizer ----\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ðŸ”¥ Recommended for fine-tuning: lower LR\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG[\"LR\"] * 0.1)\n",
    "print(\"âš¡ Using LR =\", CONFIG[\"LR\"] * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01316e99-6334-4206-b382-5b06000cb9dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1770858/1606758852.py:8: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/home/behzadhassan/anaconda3/envs/dl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1770858/1606758852.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Extra Epoch 1/10: 100%|â–ˆ| 1612/1612 [07:49<00:00,  3.43it/s, loss=0.315, acc=0.8\n",
      "/tmp/ipykernel_1770858/1606758852.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8905\n",
      "ðŸ”¥ Saved improved ResNet50: 0.8905275099262621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extra Epoch 2/10: 100%|â–ˆ| 1612/1612 [07:32<00:00,  3.56it/s, loss=0.276, acc=0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extra Epoch 3/10: 100%|â–ˆ| 1612/1612 [07:39<00:00,  3.51it/s, loss=0.271, acc=0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extra Epoch 4/10: 100%|â–ˆ| 1612/1612 [07:32<00:00,  3.56it/s, loss=0.293, acc=0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8972\n",
      "ðŸ”¥ Saved improved ResNet50: 0.897246825777739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extra Epoch 5/10: 100%|â–ˆ| 1612/1612 [07:35<00:00,  3.54it/s, loss=0.27, acc=0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extra Epoch 6/10: 100%|â–ˆ| 1612/1612 [07:33<00:00,  3.56it/s, loss=0.259, acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8989\n",
      "ðŸ”¥ Saved improved ResNet50: 0.8989048387800515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extra Epoch 7/10: 100%|â–ˆ| 1612/1612 [07:32<00:00,  3.56it/s, loss=0.376, acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extra Epoch 8/10: 100%|â–ˆ| 1612/1612 [07:35<00:00,  3.54it/s, loss=0.178, acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9027\n",
      "ðŸ”¥ Saved improved ResNet50: 0.9027444478380383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extra Epoch 9/10: 100%|â–ˆ| 1612/1612 [07:32<00:00,  3.56it/s, loss=0.307, acc=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extra Epoch 10/10: 100%|â–ˆ| 1612/1612 [07:32<00:00,  3.56it/s, loss=0.236, acc=0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8996\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# ðŸ“Œ CELL 6 â€” Continue Training (10 Epochs)\n",
    "# =====================================\n",
    "\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "EXTRA_EPOCHS = 10\n",
    "scaler = GradScaler()\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(EXTRA_EPOCHS):\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f\"Extra Epoch {epoch+1}/{EXTRA_EPOCHS}\")\n",
    "\n",
    "    for imgs, labels in pbar:\n",
    "        imgs = imgs.to(CONFIG[\"DEVICE\"])\n",
    "        labels = labels.to(CONFIG[\"DEVICE\"])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            \"loss\": loss.item(),\n",
    "            \"acc\": train_correct/train_total\n",
    "        })\n",
    "\n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs = imgs.to(CONFIG[\"DEVICE\"])\n",
    "            labels = labels.to(CONFIG[\"DEVICE\"])\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(imgs)\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    # Save if improved\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_resnet50_defacto.pth\")\n",
    "        print(\"ðŸ”¥ Saved improved ResNet50:\", best_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f93bf78b-8419-4d14-891d-ca9ff0694353",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"best_resnet50_defacto2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f55576a2-99cc-4818-a509-4ed270fabce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prediction cell ready to use!\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# ðŸ“Œ CELL â€” Predict Class from Image\n",
    "# =====================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# ---- CLASS MAPPING ----\n",
    "CLASS_NAMES = [\"splicing\", \"copymove\", \"inpainting\", \"face\"]\n",
    "\n",
    "# ---- LOAD MODEL ----\n",
    "def load_resnet_model(weights_path=\"best_resnet50_defacto.pth\"):\n",
    "    model = models.resnet50(weights=None)\n",
    "    model.fc = nn.Linear(2048, 4)\n",
    "\n",
    "    # Load checkpoint\n",
    "    state = torch.load(weights_path, map_location=\"cpu\")\n",
    "\n",
    "    # Remove DataParallel prefixes if present\n",
    "    new_state = {}\n",
    "    for k, v in state.items():\n",
    "        new_state[k.replace(\"module.\", \"\")] = v\n",
    "\n",
    "    model.load_state_dict(new_state)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = load_resnet_model()\n",
    "\n",
    "# ---- PREPROCESS ----\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=(0.485, 0.456, 0.406),\n",
    "        std=(0.229, 0.224, 0.225)\n",
    "    )\n",
    "])\n",
    "\n",
    "# ---- PREDICT FUNCTION ----\n",
    "def predict_class(image_path):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    tensor = transform(img).unsqueeze(0)  # [1,3,H,W]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(tensor)\n",
    "        pred_idx = output.argmax(dim=1).item()\n",
    "        pred_class = CLASS_NAMES[pred_idx]\n",
    "\n",
    "    return pred_class\n",
    "\n",
    "print(\"âœ… Prediction cell ready to use!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39c116de-bcc6-41ff-8ce1-b9a17927d4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'copymove'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_class(\"/home/behzadhassan/DL/Defacto/1/1.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec1a627e-dcd6-4f2a-a67f-76ad8aa457ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/behzadhassan/anaconda3/envs/dl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:47<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================\n",
      " Classification Metrics\n",
      "===============================\n",
      "Accuracy :  0.9027\n",
      "Precision: 0.9091\n",
      "Recall   : 0.9027\n",
      "F1-score : 0.9053\n",
      "===============================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    splicing       0.96      0.91      0.93     10639\n",
      "    copymove       0.56      0.60      0.58      1820\n",
      "  inpainting       0.68      0.77      0.72      2500\n",
      "        face       1.00      1.00      1.00      7960\n",
      "\n",
      "    accuracy                           0.90     22919\n",
      "   macro avg       0.80      0.82      0.81     22919\n",
      "weighted avg       0.91      0.90      0.91     22919\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# ðŸ“Œ Evaluate Classification Model (Accuracy, Precision, Recall, F1)\n",
    "# ====================================================\n",
    "from torchvision import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------------------\n",
    "# Load trained classification model\n",
    "# -----------------------------------------\n",
    "def load_resnet_model(weights_path=\"best_resnet50_defacto.pth\"):\n",
    "    model = models.resnet50(weights=None)\n",
    "    model.fc = nn.Linear(2048, 4)\n",
    "\n",
    "    # Load weights\n",
    "    state = torch.load(weights_path, map_location=\"cpu\")\n",
    "\n",
    "    # Remove \"module.\" from DataParallel\n",
    "    clean_state = {}\n",
    "    for k, v in state.items():\n",
    "        clean_state[k.replace(\"module.\", \"\")] = v\n",
    "\n",
    "    model.load_state_dict(clean_state)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = load_resnet_model()\n",
    "model = model.to(CONFIG[\"DEVICE\"])\n",
    "model.eval()\n",
    "\n",
    "# -----------------------------------------\n",
    "# Evaluate on validation set\n",
    "# -----------------------------------------\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "        imgs = imgs.to(CONFIG[\"DEVICE\"])\n",
    "        labels = labels.to(CONFIG[\"DEVICE\"])\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# -----------------------------------------\n",
    "# Compute metrics\n",
    "# -----------------------------------------\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    all_labels, all_preds, average=\"weighted\"\n",
    ")\n",
    "\n",
    "print(\"\\n===============================\")\n",
    "print(\" Classification Metrics\")\n",
    "print(\"===============================\")\n",
    "print(f\"Accuracy :  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1-score : {f1:.4f}\")\n",
    "print(\"===============================\\n\")\n",
    "\n",
    "# Optional â€” per class report\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"splicing\", \"copymove\", \"inpainting\", \"face\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b55ed35-79cc-47f4-9c59-10439c6db3d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DL)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
